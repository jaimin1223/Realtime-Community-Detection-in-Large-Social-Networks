{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Load the Email-Eu-Core dataset\n",
    "G = nx.read_edgelist(\"C:\\MTech\\Second Semester\\Web and Social Computing(IT752)\\Project\\email-Eu-core.txt\")\n",
    "G1 = nx.read_edgelist(\"C:\\MTech\\Second Semester\\Web and Social Computing(IT752)\\Project\\email-Eu-core.txt\")\n",
    "# Choose some seed nodes from the dataset as input\n",
    "#seeds = ['500', '2500', '9000', '25000', '50000', '80000', '125000', '160000', '200000', '245000']\n",
    "\n",
    "\n",
    "# candidates is a list of data points\n",
    "# num_seeds is the desired number of seed points\n",
    "# set the random seed to ensure reproducibility\n",
    "#random.seed(42)\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "print(num_nodes)\n",
    "print(num_edges)\n",
    "seeds = random.sample(list(G.nodes), 15)\n",
    "print(seeds)\n",
    "\n",
    "# Define the number of hash functions\n",
    "num_hashes = 400\n",
    "\n",
    "# Define the number of bands\n",
    "num_bands = 100\n",
    "\n",
    "# Define the number of rows per band\n",
    "rows_per_band = num_hashes // num_bands\n",
    "\n",
    "# Define the prime number for hashing\n",
    "prime = 4294967311\n",
    "\n",
    "# Define the maximum hash value\n",
    "max_hash = 2**32 - 1\n",
    "\n",
    "# Define the minhash signature function\n",
    "def minhash_signature(node, num_hashes):\n",
    "    # Generate a random permutation of the node neighbors\n",
    "    neighbors = list(G.neighbors(node))\n",
    "    random.shuffle(neighbors)\n",
    "\n",
    "    # Define the hash functions\n",
    "    def hash_function(a, b, x):\n",
    "        return ((a * x + b) % prime) % max_hash\n",
    "\n",
    "    # Generate the minhash signature\n",
    "    signature = []\n",
    "    for i in range(num_hashes):\n",
    "        min_hash = float('inf')\n",
    "        for neighbor in neighbors:\n",
    "            hash_value = hash_function(i+1, i+1, int(neighbor))\n",
    "            if hash_value < min_hash:\n",
    "                min_hash = hash_value\n",
    "        signature.append(min_hash)\n",
    "    return signature\n",
    "\n",
    "# Define the LSH function\n",
    "def LSH(seed, candidates, num_hashes, num_bands, rows_per_band):\n",
    "    # Generate the minhash signatures for the seed and candidate nodes\n",
    "    seed_signature = minhash_signature(seed, num_hashes)\n",
    "    candidate_signatures = [minhash_signature(candidate, num_hashes) for candidate in candidates]\n",
    "\n",
    "    # Define the bands\n",
    "    bands = []\n",
    "    for i in range(num_bands):\n",
    "        band = []\n",
    "        for j in range(rows_per_band):\n",
    "            band.append(i * rows_per_band + j)\n",
    "        bands.append(band)\n",
    "\n",
    "    # Define the hash table\n",
    "    hash_table = {}\n",
    "    for i, candidate_signature in enumerate(candidate_signatures):\n",
    "        for band in bands:\n",
    "            key = tuple(candidate_signature[j] for j in band)\n",
    "            if key not in hash_table:\n",
    "                hash_table[key] = []\n",
    "            hash_table[key].append(i)\n",
    "\n",
    "    # Find the candidates that are near to the seed\n",
    "    near_candidates = set()\n",
    "    for band in bands:\n",
    "        key = tuple(seed_signature[j] for j in band)\n",
    "        if key in hash_table:\n",
    "            near_candidates.update(hash_table[key])\n",
    "    return near_candidates\n",
    "\n",
    "#Following set is going to have all candidate values that are related to atleast one of the input seeds\n",
    "absolute_candidate_set = set()\n",
    "list_of_candidate_sets = []\n",
    "# Apply the LSH function to each input seed node\n",
    "for seed in seeds:\n",
    "    candidates = list(G.nodes())\n",
    "    candidates.remove(seed)\n",
    "    near_candidates = LSH(seed, candidates, num_hashes, num_bands, rows_per_band)\n",
    "    list_of_candidate_sets.append(near_candidates)\n",
    "    absolute_candidate_set = absolute_candidate_set | near_candidates\n",
    "    print(f\"Seed node: {seed}\")\n",
    "    print(f\"Near candidates: {near_candidates}\")\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(absolute_candidate_set)\n",
    "print(\"number of all total candidates = \" + str(len(absolute_candidate_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "def select_related_candidates(seeds, candidates, k):\n",
    "    \"\"\"\n",
    "    Select the k candidates that are most associated with the seed set\n",
    "    \n",
    "    Parameters:\n",
    "    - seeds: set\n",
    "        The set of seed accounts\n",
    "    - candidates: list of sets\n",
    "        The list of candidate accounts returned by LSH\n",
    "    - k: int\n",
    "        The number of candidates to select\n",
    "        \n",
    "    Returns:\n",
    "    - selected_candidates: list of sets\n",
    "        The k candidates that are most associated with the seed set\n",
    "    \"\"\"\n",
    "    # Compute the Jaccard similarity score between each candidate and the seed set\n",
    "    scores = []\n",
    "    for candidate in candidates:\n",
    "        score = len(candidate.intersection(seeds)) / len(candidate.union(seeds))\n",
    "        scores.append(score)\n",
    "\n",
    "    # Perform agglomerative clustering on the candidate set based on the similarity scores\n",
    "    clustering = AgglomerativeClustering(n_clusters=k, affinity='precomputed', linkage='complete')\n",
    "    similarity_matrix = np.array([[1 - score for score in scores]] * len(scores))\n",
    "    clustering.fit(similarity_matrix)\n",
    "\n",
    "    # Get the indices of the candidates in the largest cluster\n",
    "    cluster_sizes = [list(clustering.labels_).count(i) for i in range(k)]\n",
    "    largest_cluster_index = cluster_sizes.index(max(cluster_sizes))\n",
    "    largest_cluster_indices = [i for i in range(len(clustering.labels_)) if clustering.labels_[i] == largest_cluster_index]\n",
    "\n",
    "    # Select the candidates in the largest cluster\n",
    "    selected_candidates = [candidates[i] for i in largest_cluster_indices]\n",
    "  \n",
    "    \n",
    "    return selected_candidates\n",
    "\n",
    "\n",
    "counter = 0\n",
    "list_of_union = list()\n",
    "list_after_Agglomerative_Clustering = select_related_candidates(seeds, list_of_candidate_sets, 1)\n",
    "for candidate in list_after_Agglomerative_Clustering:\n",
    "        print(candidate)\n",
    "        list_of_union = list(set().union(list_of_union, candidate))\n",
    "        counter = counter + 1\n",
    "        if counter == 10:\n",
    "            print()\n",
    "            counter = 0\n",
    "        \n",
    "print(\"nodes after clustering = \" + str(len(list_after_Agglomerative_Clustering[0])))\n",
    "\n",
    "\"\"\"Working after agglomerative clustering\"\"\"\n",
    "nodes_to_keep = list(list_after_Agglomerative_Clustering[0])\n",
    "# nodes_to_keep = list_after_Agglomerative_Clustering[0]\n",
    "\n",
    "# nodes_to_keep = set(nodes_to_keep)\n",
    "print(\"list of union of all candidate sets----------\")\n",
    "print(list_of_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms.community import modularity\n",
    "\n",
    "Gnew = nx.read_edgelist(\"C:\\MTech\\Second Semester\\Web and Social Computing(IT752)\\Project\\email-Eu-core.txt\")\n",
    "\n",
    "Gnew = nx.convert_node_labels_to_integers(Gnew)\n",
    "approx_neighbors = set()\n",
    "approx_neighbors = list_of_union\n",
    "\n",
    "Gnewsub = G.subgraph(list(approx_neighbors))\n",
    "\n",
    "print(Gnewsub)\n",
    "\n",
    "subgraph_to_consider = nx.DiGraph()\n",
    "\n",
    "# Iterate over the edges in the original graph\n",
    "for u, v in Gnew.edges():\n",
    "    #print(\"out\")\n",
    "    #print(\"u = \" + u + \", v = \" + v)\n",
    "    # If both nodes are in the set of nodes to include, add the edge to the subgraph\n",
    "    if int(u) in approx_neighbors and int(v) in approx_neighbors:\n",
    "        subgraph_to_consider.add_edge(u, v)\n",
    "        #print(\"in\")\n",
    "\n",
    "print(subgraph_to_consider)\n",
    "communities = list(greedy_modularity_communities(subgraph_to_consider))\n",
    "\n",
    "# Assign a different color to each community\n",
    "colors = [\"r\"]\n",
    "color_map = {}\n",
    "for i, comm in enumerate(communities):\n",
    "    for node in comm:\n",
    "        color_map[node] = colors[i % len(colors)]\n",
    "\n",
    "# Draw the graph with each community shown in a different color\n",
    "nx.draw_networkx(subgraph_to_consider, node_color=[color_map[node] for node in subgraph_to_consider.nodes()], node_size=20, with_labels=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(G, node1, node2):\n",
    "    succ1 = set(G.successors(node1))\n",
    "    succ2 = set(G.successors(node2))\n",
    "    \n",
    "    intersection = len(succ1.intersection(succ2))\n",
    "    union = len(succ1.union(succ2))\n",
    "    \n",
    "    if union == 0:\n",
    "        return 0.0  # Avoid division by zero error\n",
    "    \n",
    "    jaccard_index = intersection / float(union)\n",
    "    #jaccard_dist = 1 - jaccard_index\n",
    "    \n",
    "    return jaccard_index\n",
    "\n",
    "nodes = subgraph_to_consider.nodes()\n",
    "\n",
    "for i in nodes:\n",
    "    for j in nodes:\n",
    "        print(\"Jaccard similarity for\",i, \"and\", j, \"is :\", jaccard_distance(subgraph_to_consider, i, j))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the Jaccard distance matrix\n",
    "jac = np.zeros((subgraph_to_consider.number_of_nodes(), subgraph_to_consider.number_of_nodes()))\n",
    "for i, u in enumerate(subgraph_to_consider.nodes()):\n",
    "    for j, v in enumerate(subgraph_to_consider.nodes()):\n",
    "        if i != j:\n",
    "            successors_u = set(subgraph_to_consider.successors(u))\n",
    "            successors_v = set(subgraph_to_consider.successors(v))\n",
    "            if len(successors_u.union(successors_v)) > 0:\n",
    "                jac[i, j] = len(successors_u.intersection(successors_v)) / len(successors_u.union(successors_v))\n",
    "\n",
    "# Convert the matrix into a graph\n",
    "jac_graph = nx.from_numpy_matrix(jac)\n",
    "\n",
    "# convert the Jaccard similarity matrix into a distance matrix\n",
    "distance_matrix = np.sort(distance.squareform(1 - jac, checks=False))\n",
    "\n",
    "# generate the hierarchical clustering and dendrogram\n",
    "linkage_matrix = hierarchy.linkage(distance_matrix, method='average')\n",
    "plt.figure(figsize=(25,25))\n",
    "dendrogram = hierarchy.dendrogram(linkage_matrix, labels=list(subgraph_to_consider.nodes()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdlib.algorithms import louvain\n",
    "from cdlib import evaluation\n",
    "g = subgraph_to_consider\n",
    "UG = g.to_undirected()\n",
    "communities = (louvain(UG))\n",
    "mod = evaluation.conductance(UG,communities)\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = set(subgraph_to_consider.nodes())\n",
    "conductance = 1.0\n",
    "for v in subgraph_to_consider.nodes():\n",
    "    Sv = set(subgraph_to_consider.neighbors(v))\n",
    "    if len(Sv) == 0:\n",
    "        continue\n",
    "    conductance_v = len(Sv - set([v])) / min(len(Sv), len(S - Sv))\n",
    "    conductance = min(conductance, conductance_v)\n",
    "\n",
    "print(f\"The conductance ratio of the graph is {conductance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cohesiveness\n",
    "n = subgraph_to_consider.number_of_nodes()\n",
    "m = subgraph_to_consider.number_of_edges()\n",
    "k = (n*(n-1))/2  # maximum number of edges for a complete graph\n",
    "cohesiveness = m / k\n",
    "\n",
    "# calculate density\n",
    "density = nx.density(subgraph_to_consider)\n",
    "\n",
    "print(\"Cohesiveness:\", cohesiveness)\n",
    "print(\"Density:\", density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the edge betweenness centrality\n",
    "ebc = nx.edge_betweenness_centrality(subgraph_to_consider)\n",
    "\n",
    "# sort the edges by their betweenness centrality\n",
    "sorted_ebc = sorted(ebc.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# calculate the separability of the graph\n",
    "separability = 0\n",
    "for e, w in sorted_ebc:\n",
    "    # remove the edge with highest betweenness centrality\n",
    "    subgraph_to_consider.remove_edge(*e)\n",
    "    # check if the graph is strongly connected\n",
    "    if not nx.is_strongly_connected(subgraph_to_consider):\n",
    "        separability = w\n",
    "        break\n",
    "\n",
    "# print the separability of the graph\n",
    "print(\"Separability of the graph:\", separability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (']': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "85f619018d9bc2afe4b42a9e55ac36a34cbf4595f2cb5e75baf5af2b2cbc0c1c"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
