{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinHash & LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import networkx as nx\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Load the Email-Eu-Core dataset\n",
    "G = nx.read_edgelist(\"D:\\MTech\\SEMESTER 2\\IT752 Web and Social Computing\\WSC Project\\Dataset\\email-Eu-core\\email-Eu-core.txt\")\n",
    "\n",
    "# Choose some seed nodes from the dataset as input\n",
    "seeds = ['24', '54', '103', '150', '198', '243', '288']\n",
    "\n",
    "# Define the number of hash functions\n",
    "num_hashes = 50\n",
    "\n",
    "# Define the number of bands\n",
    "num_bands = 10\n",
    "\n",
    "# Define the number of rows per band\n",
    "rows_per_band = num_hashes // num_bands\n",
    "\n",
    "# Define the prime number for hashing\n",
    "prime = 4294967311\n",
    "\n",
    "# Define the maximum hash value\n",
    "max_hash = 2**32 - 1\n",
    "\n",
    "# Define the minhash signature function\n",
    "def minhash_signature(node, num_hashes):\n",
    "    # Generate a random permutation of the node neighbors\n",
    "    neighbors = list(G.neighbors(node))\n",
    "    random.shuffle(neighbors)\n",
    "\n",
    "    # Define the hash functions\n",
    "    def hash_function(a, b, x):\n",
    "        return ((a * x + b) % prime) % max_hash\n",
    "\n",
    "    # Generate the minhash signature\n",
    "    signature = []\n",
    "    for i in range(num_hashes):\n",
    "        min_hash = float('inf')\n",
    "        for neighbor in neighbors:\n",
    "            hash_value = hash_function(i+1, i+1, int(neighbor))\n",
    "            if hash_value < min_hash:\n",
    "                min_hash = hash_value\n",
    "        signature.append(min_hash)\n",
    "    return signature\n",
    "\n",
    "# Define the LSH function\n",
    "def LSH(seed, candidates, num_hashes, num_bands, rows_per_band):\n",
    "    # Generate the minhash signatures for the seed and candidate nodes\n",
    "    seed_signature = minhash_signature(seed, num_hashes)\n",
    "    candidate_signatures = [minhash_signature(candidate, num_hashes) for candidate in candidates]\n",
    "\n",
    "    # Define the bands\n",
    "    bands = []\n",
    "    for i in range(num_bands):\n",
    "        band = []\n",
    "        for j in range(rows_per_band):\n",
    "            band.append(i * rows_per_band + j)\n",
    "        bands.append(band)\n",
    "\n",
    "    # Define the hash table\n",
    "    hash_table = {}\n",
    "    for i, candidate_signature in enumerate(candidate_signatures):\n",
    "        for band in bands:\n",
    "            key = tuple(candidate_signature[j] for j in band)\n",
    "            if key not in hash_table:\n",
    "                hash_table[key] = []import networkx as nx\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Email-Eu-Core dataset\n",
    "G = nx.read_edgelist(\"/home/student/Desktop/222it029/Projects/WSC/WSC Project/Dataset/email-Eu-core/email-Eu-core.txt\")\n",
    "#diameter = nx.diameter(G)\n",
    "#print(diameter)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# Draw the graph using a spring layout algorithm\n",
    "pos = nx.spring_layout(G, k=0.1)\n",
    "nx.draw(G, pos, node_size=10, alpha=0.6, node_color='b', edge_color='gray', ax=ax)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "            hash_table[key].append(i)\n",
    "\n",
    "    # Find the candidates that are near to the seed\n",
    "    near_candidates = set()\n",
    "    for band in bands:\n",
    "        key = tuple(seed_signature[j] for j in band)\n",
    "        if key in hash_table:\n",
    "            near_candidates.update(hash_table[key])\n",
    "    return near_candidates\n",
    "\n",
    "#Following set is going to have all candidate values that are related to atleast one of the input seeds\n",
    "absolute_candidate_set = set()\n",
    "\n",
    "# Apply the LSH function to each input seed node\n",
    "for seed in seeds:\n",
    "    candidates = list(G.nodes())\n",
    "    candidates.remove(seed)\n",
    "    near_candidates = LSH(seed, candidates, num_hashes, num_bands, rows_per_band)\n",
    "    absolute_candidate_set = absolute_candidate_set | near_candidates\n",
    "    print(f\"Seed node: {seed}\")\n",
    "    print(f\"Near candidates: {near_candidates}\")\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(absolute_candidate_set)\n",
    "print(\"number of all total candidates = \" + str(len(absolute_candidate_set)))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Load the Email-Eu-Core dataset\n",
    "G = nx.read_edgelist(\"/home/student/Desktop/222it029/Projects/WSC/WSC Project/Dataset/email-EuAll/Email-EuAll.txt\")\n",
    "\n",
    "# Choose some seed nodes from the dataset as input\n",
    "#seeds = ['500', '2500', '9000', '25000', '50000', '80000', '125000', '160000', '200000', '245000']\n",
    "\n",
    "\n",
    "# candidates is a list of data points\n",
    "# num_seeds is the desired number of seed points\n",
    "# set the random seed to ensure reproducibility\n",
    "#random.seed(42)\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "print(num_nodes)\n",
    "print(num_edges)\n",
    "seeds = random.sample(list(G.nodes), num_nodes//15000)\n",
    "print(seeds)\n",
    "\n",
    "# Define the number of hash functions\n",
    "num_hashes = 100\n",
    "\n",
    "# Define the number of bands\n",
    "num_bands = 25\n",
    "\n",
    "# Define the number of rows per band\n",
    "rows_per_band = num_hashes // num_bands\n",
    "\n",
    "# Define the prime number for hashing\n",
    "prime = 4294967311\n",
    "\n",
    "# Define the maximum hash value\n",
    "max_hash = 2**32 - 1\n",
    "\n",
    "# Define the minhash signature function\n",
    "def minhash_signature(node, num_hashes):\n",
    "    # Generate a random permutation of the node neighbors\n",
    "    neighbors = list(G.neighbors(node))\n",
    "    random.shuffle(neighbors)\n",
    "\n",
    "    # Define the hash functions\n",
    "    def hash_function(a, b, x):\n",
    "        return ((a * x + b) % prime) % max_hash\n",
    "\n",
    "    # Generate the minhash signature\n",
    "    signature = []\n",
    "    for i in range(num_hashes):\n",
    "        min_hash = float('inf')\n",
    "        for neighbor in neighbors:\n",
    "            hash_value = hash_function(i+1, i+1, int(neighbor))\n",
    "            if hash_value < min_hash:\n",
    "                min_hash = hash_value\n",
    "        signature.append(min_hash)\n",
    "    return signature\n",
    "\n",
    "# Define the LSH function\n",
    "def LSH(seed, candidates, num_hashes, num_bands, rows_per_band):\n",
    "    # Generate the minhash signatures for the seed and candidate nodes\n",
    "    seed_signature = minhash_signature(seed, num_hashes)\n",
    "    candidate_signatures = [minhash_signature(candidate, num_hashes) for candidate in candidates]\n",
    "\n",
    "    # Define the bands\n",
    "    bands = []\n",
    "    for i in range(num_bands):\n",
    "        band = []\n",
    "        for j in range(rows_per_band):\n",
    "            band.append(i * rows_per_band + j)\n",
    "        bands.append(band)\n",
    "\n",
    "    # Define the hash table\n",
    "    hash_table = {}\n",
    "    for i, candidate_signature in enumerate(candidate_signatures):\n",
    "        for band in bands:\n",
    "            key = tuple(candidate_signature[j] for j in band)\n",
    "            if key not in hash_table:\n",
    "                hash_table[key] = []\n",
    "            hash_table[key].append(i)\n",
    "\n",
    "    # Find the candidates that are near to the seed\n",
    "    near_candidates = set()\n",
    "    for band in bands:\n",
    "        key = tuple(seed_signature[j] for j in band)\n",
    "        if key in hash_table:\n",
    "            near_candidates.update(hash_table[key])\n",
    "    return near_candidates\n",
    "\n",
    "#Following set is going to have all candidate values that are related to atleast one of the input seeds\n",
    "absolute_candidate_set = set()\n",
    "list_of_candidate_sets = []\n",
    "# Apply the LSH function to each input seed node\n",
    "for seed in seeds:\n",
    "    candidates = list(G.nodes())\n",
    "    candidates.remove(seed)\n",
    "    near_candidates = LSH(seed, candidates, num_hashes, num_bands, rows_per_band)\n",
    "    list_of_candidate_sets.append(near_candidates)\n",
    "    absolute_candidate_set = absolute_candidate_set | near_candidates\n",
    "    print(f\"Seed node: {seed}\")\n",
    "    print(f\"Near candidates: {near_candidates}\")\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(absolute_candidate_set)\n",
    "print(\"number of all total candidates = \" + str(len(absolute_candidate_set)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "def select_related_candidates(seeds, candidates, k):\n",
    "    \"\"\"\n",
    "    Select the k candidates that are most associated with the seed set\n",
    "    \n",
    "    Parameters:\n",
    "    - seeds: set\n",
    "        The set of seed accounts\n",
    "    - candidates: list of sets\n",
    "        The list of candidate accounts returned by LSH\n",
    "    - k: int\n",
    "        The number of candidates to select\n",
    "        \n",
    "    Returns:\n",
    "    - selected_candidates: list of sets\n",
    "        The k candidates that are most associated with the seed set\n",
    "    \"\"\"\n",
    "    # Compute the Jaccard similari ty score between each candidate and the seed set\n",
    "    scores = []\n",
    "    for candidate in candidates:\n",
    "        score = len(candidate.intersection(seeds)) / len(candidate.union(seeds))\n",
    "        scores.append(score)\n",
    "\n",
    "    # Perform agglomerative clustering on the candidate set based on the similarity scores\n",
    "    clustering = AgglomerativeClustering(n_clusters=k, affinity='precomputed', linkage='complete')\n",
    "    similarity_matrix = np.array([[1 - score for score in scores]] * len(scores))\n",
    "    clustering.fit(similarity_matrix)\n",
    "\n",
    "    # Get the indices of the candidates in the largest cluster\n",
    "    cluster_sizes = [list(clustering.labels_).count(i) for i in range(k)]\n",
    "    largest_cluster_index = cluster_sizes.index(max(cluster_sizes))\n",
    "    largest_cluster_indices = [i for i in range(len(clustering.labels_)) if clustering.labels_[i] == largest_cluster_index]\n",
    "\n",
    "    # Select the candidates in the largest cluster\n",
    "    selected_candidates = [candidates[i] for i in largest_cluster_indices]\n",
    "  \n",
    "    \n",
    "    return selected_candidates\n",
    "\n",
    "\n",
    "counter = 0\n",
    "list_after_Agglomerative_Clustering = select_related_candidates(seeds, list_of_candidate_sets, 17)\n",
    "for candidate in list_after_Agglomerative_Clustering:\n",
    "        print(candidate)\n",
    "        counter = counter + 1\n",
    "        if counter == 10:\n",
    "            print()\n",
    "            counter = 0\n",
    "        \n",
    "print(\"nodes after clustering = \" + str(len(list_after_Agglomerative_Clustering[0])))\n",
    "\n",
    "\"\"\"Working after agglomerative clustering\"\"\"\n",
    "nodes_to_keep = list(list_after_Agglomerative_Clustering[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "nodes_to_keep = set(nodes_to_keep)\n",
    "H = G.subgraph(nodes_to_keep)\n",
    "print(\"printing subgraph\")\n",
    "print(H)\n",
    "\n",
    "subgraph_to_consider = nx.Graph()\n",
    "\n",
    "# Iterate over the edges in the original graph\n",
    "for u, v in G.edges():\n",
    "    print(\"out\")\n",
    "    print(\"u = \" + u + \", v = \" + v)\n",
    "    # If both nodes are in the set of nodes to include, add the edge to the subgraph\n",
    "    if u in nodes_to_keep and v in nodes_to_keep:\n",
    "        subgraph_to_consider.add_edge(u, v)\n",
    "        print(\"in\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_to_consider = nx.Graph()\n",
    "\n",
    "# Iterate over the edges in the original graph\n",
    "for u, v in G.edges():\n",
    "\n",
    "    # If both nodes are in the set of nodes to include, add the edge to the subgraph\n",
    "    if u in nodes_to_keep and v in nodes_to_keep:\n",
    "        subgraph_to_consider.add_edge(u, v)\n",
    "\n",
    "\n",
    "print(subgraph_to_consider.nodes())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
